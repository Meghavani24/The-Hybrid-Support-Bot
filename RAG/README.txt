ğŸ“ŒProject Title â€” Hybrid Support Bot (Advanced RAG)
ğŸ§¾ Task Chosen

Option 1: The â€œHybridâ€ Support Bot (Advanced RAG)
A Retrieval-Augmented Generation (RAG) system that answers user queries based on a technical PDF manual, using metadata filtering, hybrid vector search, and latency logging to improve accuracy.

âš™ï¸ Local Setup & Running Instructions

1. Clone the Repository

git clone <your_repo_link_here>
cd <repo_folder>

2.. Install Dependencies

pip install -r requirements.txt

3.Start Ollama (for Local Llama Model)

ollama pull llama3.2

4.Run the Ingestion Pipeline (One-time only)

This step extracts chapters, chunks the data, embeds, and builds the FAISS index.

python chapter_extractor.py
python chunk_and_embed.py
python save_faiss_index.py


5. Run Query API

Open Jupyter Notebook or Python shell:

from rag_query import answer_query
answer_query("How do I adjust the seats?", chapter="Before Driving")


ğŸ“Œ Why These Libraries & Models Were Chosen:

| Component      | Choice                                     | Reason                                                                       |
| -------------- | ------------------------------------------ | ---------------------------------------------------------------------------- |
| Embeddings     | `sentence-transformers / all-MiniLM-L6-v2` | Fast, lightweight, high accuracy for semantic search                         |
| Vector DB      | FAISS                                      | Highly optimized similarity search with low retrieval latency                |
| LLM            | `Llama 3.2` via local Ollama               | Runs offline, no API costs, deterministic + fast, allowed for the assignment |
| PDF Parser     | PyMuPDF (`fitz`)                           | High fidelity text extraction from structured manuals                        |
| Numpy / Pickle | Array storage + metadata persistence       | Efficient & minimal overhead                                                 |


ğŸ“‚ Repository Structure:

project/
â”‚
â”œâ”€ data/
â”‚   â””â”€ honda_manual.pdf
â”‚
â”œâ”€ index/
â”‚   â””â”€ amaze_index.faiss
â”‚   â””â”€ amaze_meta.pkl
â”‚
â”œâ”€ rag_emb.py        â†’ Embedding model
â”œâ”€ rag_ingest.py     â†’ PDF ingestion + chunking
â”œâ”€ rag_index.py      â†’ Build index (semantic + BM25)
â”œâ”€ rag_query.py      â†’ Hybrid search + LLM + threshold + logging
â”‚
â”œâ”€ requirements.txt
â””â”€ README.md
